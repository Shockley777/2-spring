import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import wasserstein_distance, pearsonr, entropy
from sklearn.metrics.pairwise import cosine_similarity
from scipy.ndimage import gaussian_filter1d
import os
from matplotlib.cm import get_cmap
from sklearn.model_selection import KFold
import warnings
warnings.filterwarnings('ignore')

# -------- å‚æ•°é…ç½® --------
MAIN_FOLDERS = ['20250321', '20250410', '20250414', '20250421']
# æ¯ä¸ªä¸»æ–‡ä»¶å¤¹ä¸‹çš„å­æ–‡ä»¶å¤¹
SUB_FOLDERS = {
    '20250321': ['20250322', '20250323', '20250324', '20250325', '20250326', 
                 '20250327', '20250328', '20250329', '20250330', '20250331', '20250401'],
    '20250410': ['20250411', '20250412', '20250413', '20250414'],
    '20250414': ['20250415', '20250416', '20250417', '20250418', '20250419', '20250420', '20250421'],
    '20250421': ['20250422', '20250423 5PM', '20250424 5PM', '20250425 5PM', 
                 '20250426 5PM', '20250427 5PM', '20250428 9AM']
}

AREA_COL = "area"
RATIO_OTHER = 0.5
RATIO_REF = 0.6
BINS = 60
RANGE = (500, 3500)
TOP_K = 5
N_FOLDS = 5  # 5æŠ˜äº¤å‰éªŒè¯

# åˆ›å»ºç»“æžœæ–‡ä»¶å¤¹
if not os.path.exists("results_cv"):
    os.makedirs("results_cv")

# -------- ç›¸ä¼¼åº¦å‡½æ•° --------
def compute_histogram_similarity(hist1, hist2, method='cosine'):
    hist1 = np.asarray(hist1, dtype=np.float64) + 1e-10
    hist2 = np.asarray(hist2, dtype=np.float64) + 1e-10
    if method == 'cosine':
        return float(cosine_similarity([hist1], [hist2])[0][0])
    elif method == 'correlation':
        return pearsonr(hist1, hist2)[0]
    elif method == 'intersection':
        return np.sum(np.minimum(hist1, hist2)) / np.sum(np.maximum(hist1, hist2))
    elif method == 'chi2':
        return 0.5 * np.sum((hist1 - hist2) ** 2 / (hist1 + hist2))
    elif method == 'kl':
        return entropy(hist1, hist2)
    elif method == 'wasserstein':
        return wasserstein_distance(hist1, hist2)
    else:
        raise ValueError("Unsupported similarity method")

# -------- åŠ è½½ä¸Žé‡‡æ · --------
def load_histogram(main_folder, sub_folder, ratio):
    # å°è¯•ä¸åŒçš„è·¯å¾„ç»“æž„
    possible_paths = [
        os.path.join(main_folder, sub_folder, "total", "merged.csv"),
        os.path.join(main_folder, sub_folder, "A", "total", "merged.csv"),
        os.path.join(main_folder, sub_folder, "B", "total", "merged.csv"),
        os.path.join(main_folder, sub_folder, "C", "total", "merged.csv")
    ]
    
    csv_path = None
    for path in possible_paths:
        if os.path.exists(path):
            csv_path = path
            break
    
    if csv_path is None:
        return None, None
    
    df = pd.read_csv(csv_path)
    
    # ä»…ä¿ç•™é¢ç§¯åœ¨æŒ‡å®šèŒƒå›´å†…çš„æ•°æ®
    area_data = df[AREA_COL].dropna()
    area_data = area_data[(area_data >= RANGE[0]) & (area_data <= RANGE[1])].values

    # å¦‚æžœæ•°æ®ä¸è¶³åˆ™è·³è¿‡
    if len(area_data) < 5:
        return None, None

    np.random.shuffle(area_data)
    sampled = area_data[:int(len(area_data) * ratio)]

    bins = np.linspace(RANGE[0], RANGE[1], BINS + 1)
    hist, _ = np.histogram(sampled, bins=bins, density=True)
    bin_centers = 0.5 * (bins[:-1] + bins[1:])
    return hist, bin_centers

# -------- èŽ·å–æ‰€æœ‰å¯ç”¨æ ·æœ¬ --------
def get_all_available_samples():
    """èŽ·å–æ‰€æœ‰å¯ç”¨çš„æ ·æœ¬åˆ—è¡¨"""
    available_samples = []
    
    for main_folder in MAIN_FOLDERS:
        for sub_folder in SUB_FOLDERS[main_folder]:
            folder_key = f"{main_folder}_{sub_folder}"
            hist, _ = load_histogram(main_folder, sub_folder, RATIO_OTHER)
            if hist is not None:
                available_samples.append({
                    'folder_key': folder_key,
                    'main_folder': main_folder,
                    'sub_folder': sub_folder,
                    'histogram': hist
                })
    
    return available_samples

# -------- å•æ¬¡ç›¸ä¼¼åº¦åˆ†æž --------
def run_single_analysis(reference_sample, other_samples, fold_idx):
    """è¿è¡Œå•æ¬¡ç›¸ä¼¼åº¦åˆ†æž"""
    print(f"\nðŸ”„ ç¬¬ {fold_idx + 1} æŠ˜åˆ†æž - å‚è€ƒæ ·æœ¬: {reference_sample['folder_key']}")
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    similarity_data = []
    for sample in other_samples:
        similarity_data.append({
            "Compared Folder": sample['folder_key'],
            "Reference Folder": reference_sample['folder_key'],
            "Fold": fold_idx + 1,
            "Cosine Similarity": compute_histogram_similarity(reference_sample['histogram'], sample['histogram'], 'cosine'),
            "Pearson Correlation": compute_histogram_similarity(reference_sample['histogram'], sample['histogram'], 'correlation'),
            "Histogram Intersection": compute_histogram_similarity(reference_sample['histogram'], sample['histogram'], 'intersection'),
            "Chi-Square Distance": compute_histogram_similarity(reference_sample['histogram'], sample['histogram'], 'chi2'),
            "KL Divergence": compute_histogram_similarity(reference_sample['histogram'], sample['histogram'], 'kl'),
            "Wasserstein Distance": compute_histogram_similarity(reference_sample['histogram'], sample['histogram'], 'wasserstein')
        })
    
    return pd.DataFrame(similarity_data)

# -------- ä¸»æ‰§è¡Œé€»è¾‘ --------
def main():
    print("ðŸ”¬ DATASET3 5æŠ˜äº¤å‰éªŒè¯ç›¸ä¼¼åº¦åˆ†æž")
    print("="*60)
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    
    # èŽ·å–æ‰€æœ‰å¯ç”¨æ ·æœ¬
    print("ðŸ“Š åŠ è½½æ‰€æœ‰æ ·æœ¬...")
    all_samples = get_all_available_samples()
    print(f"âœ… å…±æ‰¾åˆ° {len(all_samples)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
    
    if len(all_samples) < N_FOLDS:
        print(f"âŒ æ ·æœ¬æ•°é‡ ({len(all_samples)}) å°‘äºŽæŠ˜æ•° ({N_FOLDS})ï¼Œæ— æ³•è¿›è¡Œäº¤å‰éªŒè¯")
        return
    
    # 5æŠ˜äº¤å‰éªŒè¯
    all_results = []
    fold_results = []
    
    # éšæœºé€‰æ‹©5ä¸ªä¸åŒçš„å‚è€ƒæ ·æœ¬
    np.random.shuffle(all_samples)
    reference_samples = all_samples[:N_FOLDS]
    
    for fold_idx, reference_sample in enumerate(reference_samples):
        print(f"\nðŸ”„ ç¬¬ {fold_idx + 1} æŠ˜åˆ†æž")
        print(f"   å‚è€ƒæ ·æœ¬: {reference_sample['folder_key']}")
        
        # å…¶ä»–æ ·æœ¬ä½œä¸ºæµ‹è¯•é›†
        other_samples = [s for s in all_samples if s['folder_key'] != reference_sample['folder_key']]
        
        # è¿è¡Œåˆ†æž
        fold_df = run_single_analysis(reference_sample, other_samples, fold_idx)
        all_results.append(fold_df)
        
        # ç»Ÿè®¡å½“å‰æŠ˜çš„ç»“æžœ
        fold_stats = {
            'fold': fold_idx + 1,
            'reference': reference_sample['folder_key'],
            'mean_intersection': fold_df['Histogram Intersection'].mean(),
            'std_intersection': fold_df['Histogram Intersection'].std(),
            'max_intersection': fold_df['Histogram Intersection'].max(),
            'min_intersection': fold_df['Histogram Intersection'].min(),
            'sample_count': len(fold_df)
        }
        fold_results.append(fold_stats)
        
        print(f"   å¹³å‡ç›¸ä¼¼åº¦: {fold_stats['mean_intersection']:.4f} Â± {fold_stats['std_intersection']:.4f}")
    
    # åˆå¹¶æ‰€æœ‰ç»“æžœ
    combined_df = pd.concat(all_results, ignore_index=True)
    
    # ä¿å­˜è¯¦ç»†ç»“æžœ
    combined_df.to_excel("results_cv/all_folds_similarity_results.xlsx", index=False)
    
    # åˆ›å»ºæŠ˜é—´ç»Ÿè®¡
    fold_summary = pd.DataFrame(fold_results)
    fold_summary.to_excel("results_cv/fold_summary.xlsx", index=False)
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    print(f"\nðŸ“Š 5æŠ˜äº¤å‰éªŒè¯æ€»ä½“ç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(all_samples)}")
    print(f"   å¹³å‡ç›¸ä¼¼åº¦: {combined_df['Histogram Intersection'].mean():.4f} Â± {combined_df['Histogram Intersection'].std():.4f}")
    print(f"   ç›¸ä¼¼åº¦èŒƒå›´: {combined_df['Histogram Intersection'].min():.4f} - {combined_df['Histogram Intersection'].max():.4f}")
    
    # æŠ˜é—´æ¯”è¾ƒ
    print(f"\nðŸ”„ å„æŠ˜ç»“æžœæ¯”è¾ƒ:")
    for _, row in fold_summary.iterrows():
        print(f"   ç¬¬{row['fold']}æŠ˜ ({row['reference']}): {row['mean_intersection']:.4f} Â± {row['std_intersection']:.4f}")
    
    # æ‰¾å‡ºæœ€ç¨³å®šçš„å‚è€ƒæ ·æœ¬
    most_stable_fold = fold_summary.loc[fold_summary['std_intersection'].idxmin()]
    print(f"\nðŸ† æœ€ç¨³å®šçš„å‚è€ƒæ ·æœ¬: ç¬¬{most_stable_fold['fold']}æŠ˜ ({most_stable_fold['reference']})")
    print(f"   æ ‡å‡†å·®: {most_stable_fold['std_intersection']:.4f}")
    
    # å¯è§†åŒ–ï¼šæŠ˜é—´æ¯”è¾ƒ
    plt.figure(figsize=(12, 8))
    
    # ç®±çº¿å›¾æ¯”è¾ƒå„æŠ˜ç»“æžœ
    plt.subplot(2, 2, 1)
    fold_data = [combined_df[combined_df['Fold'] == i+1]['Histogram Intersection'].values 
                 for i in range(N_FOLDS)]
    plt.boxplot(fold_data, labels=[f'Fold {i+1}' for i in range(N_FOLDS)])
    plt.title('å„æŠ˜ç›¸ä¼¼åº¦åˆ†å¸ƒæ¯”è¾ƒ')
    plt.ylabel('ç›´æ–¹å›¾äº¤é›†ç›¸ä¼¼åº¦')
    plt.xticks(rotation=45)
    
    # æŠ˜é—´ç»Ÿè®¡å›¾
    plt.subplot(2, 2, 2)
    x_pos = np.arange(len(fold_summary))
    plt.bar(x_pos, fold_summary['mean_intersection'], 
            yerr=fold_summary['std_intersection'], capsize=5)
    plt.title('å„æŠ˜å¹³å‡ç›¸ä¼¼åº¦')
    plt.ylabel('å¹³å‡ç›¸ä¼¼åº¦')
    plt.xticks(x_pos, [f'Fold {i+1}' for i in range(N_FOLDS)], rotation=45)
    
    # å‚è€ƒæ ·æœ¬å½±å“åˆ†æž
    plt.subplot(2, 2, 3)
    plt.scatter(fold_summary['mean_intersection'], fold_summary['std_intersection'], s=100)
    for i, row in fold_summary.iterrows():
        plt.annotate(f"Fold {row['fold']}", 
                    (row['mean_intersection'], row['std_intersection']),
                    xytext=(5, 5), textcoords='offset points')
    plt.xlabel('å¹³å‡ç›¸ä¼¼åº¦')
    plt.ylabel('ç›¸ä¼¼åº¦æ ‡å‡†å·®')
    plt.title('å‚è€ƒæ ·æœ¬ç¨³å®šæ€§åˆ†æž')
    
    # æ€»ä½“ç›¸ä¼¼åº¦åˆ†å¸ƒ
    plt.subplot(2, 2, 4)
    plt.hist(combined_df['Histogram Intersection'], bins=20, alpha=0.7, edgecolor='black')
    plt.axvline(combined_df['Histogram Intersection'].mean(), color='red', linestyle='--', 
                label=f'å‡å€¼: {combined_df["Histogram Intersection"].mean():.3f}')
    plt.xlabel('ç›´æ–¹å›¾äº¤é›†ç›¸ä¼¼åº¦')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('æ€»ä½“ç›¸ä¼¼åº¦åˆ†å¸ƒ')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig("results_cv/cross_validation_analysis.png", dpi=300, bbox_inches='tight')
    plt.show()
    
    # è¾“å‡ºæœ€ç›¸ä¼¼çš„æ ·æœ¬ï¼ˆåŸºäºŽæ‰€æœ‰æŠ˜çš„ç»“æžœï¼‰
    print(f"\nðŸ” åŸºäºŽ5æŠ˜äº¤å‰éªŒè¯çš„æœ€ç›¸ä¼¼æ ·æœ¬ (TOP {TOP_K}):")
    overall_similarity = combined_df.groupby('Compared Folder')['Histogram Intersection'].mean().sort_values(ascending=False)
    for i, (sample, similarity) in enumerate(overall_similarity.head(TOP_K).items()):
        print(f"   {i+1}. {sample}: {similarity:.4f}")
    
    print(f"\nðŸ“ ç»“æžœå·²ä¿å­˜åˆ° results_cv/ æ–‡ä»¶å¤¹")
    print(f"   - all_folds_similarity_results.xlsx: æ‰€æœ‰æŠ˜çš„è¯¦ç»†ç»“æžœ")
    print(f"   - fold_summary.xlsx: å„æŠ˜ç»Ÿè®¡æ‘˜è¦")
    print(f"   - cross_validation_analysis.png: äº¤å‰éªŒè¯åˆ†æžå›¾")

if __name__ == "__main__":
    main() 
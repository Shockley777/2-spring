import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import random
from pathlib import Path
import warnings
import matplotlib
from scipy.interpolate import make_interp_spline
matplotlib.rcParams['font.sans-serif'] = ['Microsoft YaHei']  # æŒ‡å®šä¸­æ–‡å­—ä½“
matplotlib.rcParams['axes.unicode_minus'] = False  # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
warnings.filterwarnings('ignore')

# -------- å‚æ•°è®¾ç½® --------
AREA_COL = "area"             # é¢ç§¯åˆ—
RANGE = (500, 3500)           # é¢ç§¯åˆ†å¸ƒèŒƒå›´
BINS = 30                     # binæ•°é‡ï¼ˆä¸å‚è€ƒä»£ç ä¸€è‡´ï¼‰
STABLE_SAMPLE_SIZE = 6000     # ä»ç¨³å®šæ€§åˆ†æå¾—å‡ºçš„æ¨èæ ·æœ¬æ•°
N_RANDOM_SAMPLES = 3          # è¿›è¡Œå¤šå°‘æ¬¡éšæœºæŠ½æ ·å¯¹æ¯”
SMOOTH_POINTS = 300           # å¹³æ»‘æ›²çº¿çš„ç‚¹æ•°

def find_merged_files():
    """æŸ¥æ‰¾æ‰€æœ‰merged.csvæ–‡ä»¶"""
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œç„¶åå›åˆ°DATASET4ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    base_dir = os.path.dirname(script_dir)  # ä»comparisonå›åˆ°DATASET4
    pattern = os.path.join(base_dir, "data", "**", "total", "merged.csv")
    print(f"ğŸ” æœç´¢è·¯å¾„: {pattern}")  # è°ƒè¯•ä¿¡æ¯
    files = glob.glob(pattern, recursive=True)
    return sorted(files)

def get_file_info(file_path):
    """ä»æ–‡ä»¶è·¯å¾„æå–æ—¥æœŸå’Œæ—¶é—´ä¿¡æ¯"""
    parts = file_path.split(os.sep)
    # æ‰¾åˆ°æ—¥æœŸéƒ¨åˆ†ï¼Œé€šå¸¸æ˜¯å½¢å¦‚ "20250510"çš„æ ¼å¼
    for part in parts:
        if len(part) >= 8 and part[:8].isdigit():
            date_part = part[:8]
            time_part = part[8:].strip() if len(part) > 8 else ""
            return date_part, time_part
    return "Unknown", ""

def select_day_file(files):
    """è®©ç”¨æˆ·é€‰æ‹©è¦åˆ†æçš„æŸå¤©æ•°æ®"""
    print("ğŸ” æ‰¾åˆ°ä»¥ä¸‹æ•°æ®æ–‡ä»¶:")
    file_info = []
    for i, file_path in enumerate(files):
        date, time = get_file_info(file_path)
        file_info.append((date, time, file_path))
        print(f"   {i+1}. {date} {time}")
    
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©è¦åˆ†æçš„æ–‡ä»¶ (1-{len(files)}, æˆ–è¾“å…¥qé€€å‡º): ").strip()
            if choice.lower() == 'q':
                return None
            idx = int(choice) - 1
            if 0 <= idx < len(files):
                return files[idx]
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æ•°å­—")

def load_and_filter_data(file_path):
    """åŠ è½½æ•°æ®å¹¶è¿‡æ»¤é¢ç§¯èŒƒå›´"""
    try:
        df = pd.read_csv(file_path)
        if AREA_COL not in df.columns:
            print(f"âŒ æ–‡ä»¶ä¸­æœªæ‰¾åˆ°'{AREA_COL}'åˆ—")
            return None
        
        # è¿‡æ»¤é¢ç§¯èŒƒå›´
        area_data = df[AREA_COL].dropna()
        filtered_data = area_data[(area_data >= RANGE[0]) & (area_data <= RANGE[1])]
        
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   - æ€»ç»†èƒæ•°: {len(area_data)}")
        print(f"   - æœ‰æ•ˆèŒƒå›´å†…ç»†èƒæ•° ({RANGE[0]}-{RANGE[1]}): {len(filtered_data)}")
        print(f"   - è¿‡æ»¤æ¯”ä¾‹: {len(filtered_data)/len(area_data)*100:.1f}%")
        
        return filtered_data.values
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
        return None

def random_sample_data(data, sample_size, n_samples=1):
    """éšæœºæŠ½æ ·æ•°æ®"""
    if len(data) < sample_size:
        print(f"âš ï¸ æ•°æ®é‡ä¸è¶³ï¼Œéœ€è¦{sample_size}ä¸ªï¼Œå®é™…åªæœ‰{len(data)}ä¸ª")
        sample_size = len(data)
    
    samples = []
    for i in range(n_samples):
        sample = np.random.choice(data, size=sample_size, replace=False)
        samples.append(sample)
    
    return samples, sample_size

def calculate_smooth_curve(data):
    """æ ¹æ®æ•°æ®è®¡ç®—å¹³æ»‘æ›²çº¿"""
    # è®¡ç®—ç›´æ–¹å›¾æ•°æ®ï¼ˆä½¿ç”¨ç›¸åŒçš„åŒºé—´å’Œ bin æ•°ï¼‰
    counts, bin_edges = np.histogram(data, bins=BINS, range=RANGE)
    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])
    
    # è®¡ç®—å„åŒºé—´å æ¯”ï¼ˆå½’ä¸€åŒ–ï¼‰
    ratios = counts / np.sum(counts)
    
    # è¿›è¡Œ B-spline æ’å€¼ï¼Œä½¿æ›²çº¿å¹³æ»‘
    if len(bin_centers) >= 4:  # è‡³å°‘éœ€è¦4ä¸ªç‚¹æ‰èƒ½åšä¸‰æ¬¡B-spline
        spline = make_interp_spline(bin_centers, ratios, k=3)  # ä¸‰æ¬¡ B-spline
        x_smooth = np.linspace(bin_centers.min(), bin_centers.max(), SMOOTH_POINTS)
        y_smooth = spline(x_smooth)
        # ç¡®ä¿yå€¼éè´Ÿ
        y_smooth = np.maximum(y_smooth, 0)
    else:
        # å¦‚æœç‚¹æ•°ä¸å¤Ÿï¼Œä½¿ç”¨çº¿æ€§æ’å€¼
        x_smooth = bin_centers
        y_smooth = ratios
    
    return x_smooth, y_smooth, bin_centers, ratios

def plot_curve_comparison(full_data, sampled_data_list, actual_sample_size, file_path):
    """ç»˜åˆ¶å…¨é‡æ•°æ®ä¸é‡‡æ ·æ•°æ®çš„æ›²çº¿å¯¹æ¯”"""
    date, time = get_file_info(file_path)
    
    # åˆ›å»ºå›¾å½¢ï¼š2è¡Œ2åˆ—å¸ƒå±€
    fig = plt.figure(figsize=(16, 12))
    
    # è®¡ç®—å…¨é‡æ•°æ®çš„å¹³æ»‘æ›²çº¿
    full_x, full_y, full_centers, full_ratios = calculate_smooth_curve(full_data)
    full_mean = np.mean(full_data)
    
    # è®¡ç®—é‡‡æ ·æ•°æ®çš„å¹³æ»‘æ›²çº¿
    sample_curves = []
    sample_means = []
    for sampled_data in sampled_data_list:
        x, y, centers, ratios = calculate_smooth_curve(sampled_data)
        sample_curves.append((x, y, centers, ratios))
        sample_means.append(np.mean(sampled_data))
    
    # 1. ç»˜åˆ¶å…¨é‡æ•°æ®æ›²çº¿ (å·¦ä¸Š)
    ax1 = plt.subplot(2, 2, 1)
    ax1.plot(full_x, full_y, linewidth=2, color='blue', label='å…¨é‡æ•°æ®åˆ†å¸ƒ')
    ax1.axvline(full_mean, color='red', linestyle='--', linewidth=2, 
               label=f'å‡å€¼: {full_mean:.1f}')
    
    # æ‰¾åˆ°æœ€å¤§å€¼ç‚¹å¹¶æ ‡æ³¨
    max_idx = np.argmax(full_y)
    max_x = full_x[max_idx]
    max_y = full_y[max_idx]
    ax1.plot(max_x, max_y, 'ro', markersize=8)
    ax1.text(max_x, max_y + 0.005, f'å³°å€¼\n({max_x:.0f}, {max_y:.3f})', 
             ha='center', va='bottom', fontsize=10, color='red')
    
    ax1.set_title(f'å…¨é‡æ•°æ®åˆ†å¸ƒæ›²çº¿\n{date} {time}\n(n={len(full_data)})', 
                 fontsize=12, fontweight='bold')
    ax1.set_xlabel('ç»†èƒé¢ç§¯ (Pixel)')
    ax1.set_ylabel('é¢ç§¯å æ¯”')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_xlim(RANGE)
    
    # 2. ç»˜åˆ¶ç¨³å®šæ ·æœ¬æ›²çº¿å¯¹æ¯” (å³ä¸Š)
    ax2 = plt.subplot(2, 2, 2)
    
    # ç»˜åˆ¶å…¨é‡æ•°æ®ä½œä¸ºå‚è€ƒ
    ax2.plot(full_x, full_y, linewidth=3, color='blue', alpha=0.7, 
            label=f'å…¨é‡æ•°æ® (n={len(full_data)})')
    
    # ç»˜åˆ¶é‡‡æ ·æ•°æ®æ›²çº¿
    colors = ['red', 'green', 'orange']
    for i, (x, y, centers, ratios) in enumerate(sample_curves):
        color = colors[i % len(colors)]
        ax2.plot(x, y, linewidth=2, color=color, alpha=0.8, 
                label=f'éšæœºæ ·æœ¬ {i+1} (n={actual_sample_size})')
        
        # æ ‡æ³¨å³°å€¼ç‚¹
        max_idx = np.argmax(y)
        max_x_sample = x[max_idx]
        max_y_sample = y[max_idx]
        ax2.plot(max_x_sample, max_y_sample, 'o', color=color, markersize=6)
    
    ax2.axvline(full_mean, color='blue', linestyle='--', linewidth=2, alpha=0.7,
               label=f'å…¨é‡å‡å€¼: {full_mean:.1f}')
    
    ax2.set_title(f'ç¨³å®šæ ·æœ¬ä¸å…¨é‡æ•°æ®å¯¹æ¯”\n{N_RANDOM_SAMPLES}æ¬¡éšæœºæŠ½æ ·', 
                 fontsize=12, fontweight='bold')
    ax2.set_xlabel('ç»†èƒé¢ç§¯ (Pixel)')
    ax2.set_ylabel('é¢ç§¯å æ¯”')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_xlim(RANGE)
    
    # 3. ç»˜åˆ¶ç»Ÿè®¡æŒ‡æ ‡å¯¹æ¯” (å·¦ä¸‹)
    ax3 = plt.subplot(2, 2, 3)
    
    # å‡†å¤‡ç»Ÿè®¡æ•°æ®
    categories = ['å…¨é‡æ•°æ®'] + [f'æ ·æœ¬{i+1}' for i in range(len(sampled_data_list))]
    means = [full_mean] + sample_means
    stds = [np.std(full_data)] + [np.std(sample) for sample in sampled_data_list]
    
    # è®¡ç®—å³°å€¼ä½ç½®
    peak_positions = [full_x[np.argmax(full_y)]]
    for x, y, _, _ in sample_curves:
        peak_positions.append(x[np.argmax(y)])
    
    x_pos = np.arange(len(categories))
    width = 0.25
    
    # ç»˜åˆ¶ä¸‰ä¸ªæŒ‡æ ‡å¯¹æ¯”
    bars1 = ax3.bar(x_pos - width, means, width, label='å‡å€¼', alpha=0.8, color='skyblue')
    bars2 = ax3.bar(x_pos, stds, width, label='æ ‡å‡†å·®', alpha=0.8, color='lightcoral')
    bars3 = ax3.bar(x_pos + width, peak_positions, width, label='å³°å€¼ä½ç½®', alpha=0.8, color='lightgreen')
    
    ax3.set_xlabel('æ•°æ®ç»„')
    ax3.set_ylabel('æ•°å€¼')
    ax3.set_title('ç»Ÿè®¡æŒ‡æ ‡å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax3.set_xticks(x_pos)
    ax3.set_xticklabels(categories, rotation=45, ha='right')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
    for bars, values in [(bars1, means), (bars2, stds), (bars3, peak_positions)]:
        for bar, value in zip(bars, values):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, 
                    f'{value:.0f}', ha='center', va='bottom', fontsize=8)
    
    # 4. ç»˜åˆ¶è¯¯å·®åˆ†æ (å³ä¸‹)
    ax4 = plt.subplot(2, 2, 4)
    
    # è®¡ç®—å„ç§è¯¯å·®
    mean_errors = [abs(mean - full_mean)/full_mean*100 for mean in sample_means]
    peak_errors = [abs(pos - peak_positions[0])/peak_positions[0]*100 for pos in peak_positions[1:]]
    
    sample_labels = [f'æ ·æœ¬{i+1}' for i in range(len(sampled_data_list))]
    x_pos = np.arange(len(sample_labels))
    width = 0.35
    
    bars1 = ax4.bar(x_pos - width/2, mean_errors, width, label='å‡å€¼è¯¯å·®', alpha=0.8, color='orange')
    bars2 = ax4.bar(x_pos + width/2, peak_errors, width, label='å³°å€¼ä½ç½®è¯¯å·®', alpha=0.8, color='purple')
    
    ax4.set_xlabel('éšæœºæ ·æœ¬')
    ax4.set_ylabel('ç›¸å¯¹è¯¯å·® (%)')
    ax4.set_title('æ ·æœ¬ä»£è¡¨æ€§åˆ†æ\n(ç›¸å¯¹å…¨é‡æ•°æ®çš„è¯¯å·®)', fontsize=12, fontweight='bold')
    ax4.set_xticks(x_pos)
    ax4.set_xticklabels(sample_labels)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # æ·»åŠ è¯¯å·®é˜ˆå€¼çº¿
    ax4.axhline(y=1, color='green', linestyle='--', alpha=0.7, label='ä¼˜ç§€ (<1%)')
    ax4.axhline(y=3, color='orange', linestyle='--', alpha=0.7, label='è‰¯å¥½ (<3%)')
    ax4.axhline(y=5, color='red', linestyle='--', alpha=0.7, label='ä¸€èˆ¬ (<5%)')
    
    # æ˜¾ç¤ºå…·ä½“æ•°å€¼
    for bars, errors in [(bars1, mean_errors), (bars2, peak_errors)]:
        for bar, error in zip(bars, errors):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                    f'{error:.2f}%', ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    script_dir = os.path.dirname(os.path.abspath(__file__))
    clean_time = time.replace(' ', '_').replace(':', '')
    image_file = os.path.join(script_dir, f"curve_comparison_{date}_{clean_time}.png")
    plt.savefig(image_file, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"ğŸ“Š æ›²çº¿å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {image_file}")
    
    return image_file, mean_errors, peak_errors

def print_analysis_summary(full_data, sampled_data_list, actual_sample_size, mean_errors, peak_errors):
    """æ‰“å°åˆ†ææ€»ç»“"""
    print(f"\n" + "="*60)
    print(f"ğŸ“ˆ æ›²çº¿åˆ†ææ€»ç»“")
    print(f"="*60)
    
    full_mean = np.mean(full_data)
    full_std = np.std(full_data)
    
    # è®¡ç®—å…¨é‡æ•°æ®å³°å€¼
    full_x, full_y, _, _ = calculate_smooth_curve(full_data)
    full_peak = full_x[np.argmax(full_y)]
    
    print(f"ğŸ” å…¨é‡æ•°æ® (n={len(full_data)}):")
    print(f"   å‡å€¼: {full_mean:.2f}  |  æ ‡å‡†å·®: {full_std:.2f}  |  å³°å€¼ä½ç½®: {full_peak:.1f}")
    print(f"   èŒƒå›´: {np.min(full_data):.1f} - {np.max(full_data):.1f}")
    
    print(f"\nğŸ¯ ç¨³å®šæ ·æœ¬ (n={actual_sample_size}):")
    for i, sampled_data in enumerate(sampled_data_list):
        sample_mean = np.mean(sampled_data)
        sample_std = np.std(sampled_data)
        
        # è®¡ç®—æ ·æœ¬å³°å€¼
        sample_x, sample_y, _, _ = calculate_smooth_curve(sampled_data)
        sample_peak = sample_x[np.argmax(sample_y)]
        
        print(f"   æ ·æœ¬{i+1} - å‡å€¼: {sample_mean:.2f} | æ ‡å‡†å·®: {sample_std:.2f} | å³°å€¼: {sample_peak:.1f}")
        print(f"            è¯¯å·®: å‡å€¼Â±{mean_errors[i]:.2f}% | å³°å€¼Â±{peak_errors[i]:.2f}%")
    
    # æ€»ä½“è¯„ä¼°
    avg_mean_error = np.mean(mean_errors)
    avg_peak_error = np.mean(peak_errors)
    max_mean_error = np.max(mean_errors)
    max_peak_error = np.max(peak_errors)
    
    print(f"\nğŸ“Š ä»£è¡¨æ€§è¯„ä¼°:")
    print(f"   å¹³å‡å‡å€¼è¯¯å·®: {avg_mean_error:.2f}%  |  æœ€å¤§å‡å€¼è¯¯å·®: {max_mean_error:.2f}%")
    print(f"   å¹³å‡å³°å€¼è¯¯å·®: {avg_peak_error:.2f}%  |  æœ€å¤§å³°å€¼è¯¯å·®: {max_peak_error:.2f}%")
    
    # ç»¼åˆè¯„çº§
    overall_error = (avg_mean_error + avg_peak_error) / 2
    if overall_error < 1:
        print(f"   âœ… è¯„çº§: ä¼˜ç§€ - ç¨³å®šæ ·æœ¬æ•°({actual_sample_size})èƒ½å¾ˆå¥½ä»£è¡¨å…¨é‡æ•°æ®åˆ†å¸ƒ")
    elif overall_error < 3:
        print(f"   âœ… è¯„çº§: è‰¯å¥½ - ç¨³å®šæ ·æœ¬æ•°({actual_sample_size})åŸºæœ¬èƒ½ä»£è¡¨å…¨é‡æ•°æ®åˆ†å¸ƒ")
    elif overall_error < 5:
        print(f"   âš ï¸  è¯„çº§: ä¸€èˆ¬ - ç¨³å®šæ ·æœ¬æ•°({actual_sample_size})å‹‰å¼ºèƒ½ä»£è¡¨å…¨é‡æ•°æ®åˆ†å¸ƒ")
    else:
        print(f"   âŒ è¯„çº§: éœ€æ”¹è¿› - ç¨³å®šæ ·æœ¬æ•°({actual_sample_size})ä¸è¶³ä»¥ä»£è¡¨å…¨é‡æ•°æ®åˆ†å¸ƒ")
    
    # æ ·æœ¬è¦†ç›–ç‡
    coverage = actual_sample_size / len(full_data) * 100
    print(f"\nğŸ’° æˆæœ¬æ•ˆç›Š:")
    print(f"   æ ·æœ¬è¦†ç›–ç‡: {coverage:.1f}%")
    print(f"   æ•°æ®å‡å°‘: {100-coverage:.1f}%")
    print(f"   åˆ†å¸ƒç‰¹å¾ä¿æŒåº¦: {100-overall_error:.1f}%")

def main():
    print("ğŸ” DATASET4 é¢ç§¯åˆ†å¸ƒæ›²çº¿å¯¹æ¯”åˆ†æ")
    print("=" * 50)
    print(f"ğŸ’¡ ç›®æ ‡: éªŒè¯ç¨³å®šæ ·æœ¬æ•° {STABLE_SAMPLE_SIZE} çš„åˆ†å¸ƒæ›²çº¿ä»£è¡¨æ€§")
    print(f"ğŸ“Š åˆ†ææ–¹æ³•: å…¨é‡æ•°æ® vs {N_RANDOM_SAMPLES}æ¬¡éšæœºæŠ½æ ·å¹³æ»‘æ›²çº¿å¯¹æ¯”")
    print(f"ğŸ“ é¢ç§¯èŒƒå›´: {RANGE[0]} - {RANGE[1]}")
    print(f"ğŸ¯ æ›²çº¿å¹³æ»‘ç‚¹æ•°: {SMOOTH_POINTS}")
    
    # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
    files = find_merged_files()
    if not files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•merged.csvæ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    # é€‰æ‹©è¦åˆ†æçš„æ–‡ä»¶
    selected_file = select_day_file(files)
    if not selected_file:
        print("âŒ æœªé€‰æ‹©æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
        return
    
    date, time = get_file_info(selected_file)
    print(f"\nğŸ“… åˆ†æç›®æ ‡: {date} {time}")
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {selected_file}")
    
    # åŠ è½½æ•°æ®
    full_data = load_and_filter_data(selected_file)
    if full_data is None:
        return
    
    # éšæœºæŠ½æ ·
    print(f"\nğŸ² è¿›è¡Œ {N_RANDOM_SAMPLES} æ¬¡éšæœºæŠ½æ ·...")
    sampled_data_list, actual_sample_size = random_sample_data(full_data, STABLE_SAMPLE_SIZE, N_RANDOM_SAMPLES)
    
    # ç»˜åˆ¶æ›²çº¿å¯¹æ¯”å›¾
    print(f"\nğŸ“Š ç»˜åˆ¶åˆ†å¸ƒæ›²çº¿å¯¹æ¯”...")
    image_file, mean_errors, peak_errors = plot_curve_comparison(full_data, sampled_data_list, actual_sample_size, selected_file)
    
    # åˆ†ææ€»ç»“
    print_analysis_summary(full_data, sampled_data_list, actual_sample_size, mean_errors, peak_errors)
    
    print(f"\n" + "="*60)
    print(f"âœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š æ›²çº¿å¯¹æ¯”å›¾è¡¨: {os.path.basename(image_file)}")
    print(f"ğŸ’¡ ç»“è®º: é€šè¿‡æ›²çº¿å¯¹æ¯”éªŒè¯ç¨³å®šæ ·æœ¬æ•° {actual_sample_size} çš„åˆ†å¸ƒä»£è¡¨æ€§")

if __name__ == "__main__":
    main() 
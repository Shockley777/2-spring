import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import wasserstein_distance, pearsonr, entropy
from sklearn.metrics.pairwise import cosine_similarity
from scipy.ndimage import gaussian_filter1d
import os
from matplotlib.cm import get_cmap
import shutil
import random

# -------- å‚æ•°é…ç½® --------
days = [f"DAY{i}" for i in range(2, 8)]  # DATASET2: DAY2-DAY7
data_folders = [f"data{j}" for j in range(1, 7)]  # DATASET2: data1-data6
all_refs = [(d, f) for d in days for f in data_folders]
AREA_COL = "area"
RATIO_OTHER = 1  # å…¶ä»–æ ·æœ¬å…¨éƒ¨æ•°æ®
BINS = 60
RANGE = (500, 3500)
TOP_K = 5

# éšæœºé€‰å–5ä¸ªä¸åŒçš„å‚è€ƒæ ·æœ¬
random.seed(42)
random_refs = random.sample(all_refs, 5)

for idx, (REFERENCE_FOLDER, REFERENCE_DATA) in enumerate(random_refs, 1):
    RATIO_REF = 0.3
    result_dir = os.path.join('results', f'random_ref_{idx}_{REFERENCE_FOLDER}_{REFERENCE_DATA}')
    if not os.path.exists(result_dir):
        os.makedirs(result_dir)

    print(f"\n===== ç¬¬{idx}ç»„å‚è€ƒæ ·æœ¬: {REFERENCE_FOLDER}_{REFERENCE_DATA} (30%æ•°æ®) =====")

    # -------- ç›¸ä¼¼åº¦å‡½æ•° --------
    def compute_histogram_similarity(hist1, hist2, method='intersection'):
        hist1 = np.asarray(hist1, dtype=np.float64) + 1e-10
        hist2 = np.asarray(hist2, dtype=np.float64) + 1e-10
        if method == 'intersection':
            return np.sum(np.minimum(hist1, hist2)) / np.sum(np.maximum(hist1, hist2))
        elif method == 'kl':
            return entropy(hist1, hist2)
        else:
            raise ValueError("Unsupported similarity method")

    # -------- åŠ è½½ä¸é‡‡æ · --------
    def load_histogram(folder, data_subfolder, ratio):
        csv_path = os.path.join(folder, data_subfolder, "total", "merged.csv")
        if not os.path.exists(csv_path):
            print(f"Warning: {csv_path} not found, skipping.")
            return None, None
        df = pd.read_csv(csv_path)
        
        # ä»…ä¿ç•™é¢ç§¯åœ¨æŒ‡å®šèŒƒå›´å†…çš„æ•°æ®
        area_data = df[AREA_COL].dropna()
        area_data = area_data[(area_data >= RANGE[0]) & (area_data <= RANGE[1])].values

        # å¦‚æœæ•°æ®ä¸è¶³åˆ™è·³è¿‡
        if len(area_data) < 5:
            print(f"Warning: Too few area values in range for {folder}/{data_subfolder}, skipping.")
            return None, None

        np.random.shuffle(area_data)
        sampled = area_data[:int(len(area_data) * ratio)]

        bins = np.linspace(RANGE[0], RANGE[1], BINS + 1)
        hist, _ = np.histogram(sampled, bins=bins, density=True)
        bin_centers = 0.5 * (bins[:-1] + bins[1:])
        return hist, bin_centers

    # -------- ä¸»æ‰§è¡Œé€»è¾‘ --------
    np.random.seed(42)

    # 1. åŠ è½½å‚è€ƒç›´æ–¹å›¾
    ref_hist, bin_centers = load_histogram(REFERENCE_FOLDER, REFERENCE_DATA, RATIO_REF)
    if ref_hist is None:
        print(f"å‚è€ƒæ ·æœ¬ {REFERENCE_FOLDER}_{REFERENCE_DATA} è¯»å–å¤±è´¥ï¼Œè·³è¿‡ã€‚")
        continue

    # 2. éå†æ‰€æœ‰æ–‡ä»¶å¤¹ï¼Œæ„å»ºç›´æ–¹å›¾
    histograms = {}
    count_stats = []
    for folder in days:
        for data_subfolder in data_folders:
            folder_key = f"{folder}_{data_subfolder}"
            hist, _ = load_histogram(folder, data_subfolder, RATIO_OTHER)
            if hist is not None:
                histograms[folder_key] = hist
                # ç»Ÿè®¡ç»†èƒæ•°é‡
                csv_path = os.path.join(folder, data_subfolder, "total", "merged.csv")
                df = pd.read_csv(csv_path)
                area_series = df[AREA_COL].dropna()
                total_cells = len(area_series)
                in_range_cells = ((area_series >= RANGE[0]) & (area_series <= RANGE[1])).sum()
                count_stats.append({
                    "Folder": folder_key,
                    "Total Cells": total_cells,
                    "Cells in 500-3500": in_range_cells
                })
    # ä¿å­˜ç»†èƒæ•°é‡ç»Ÿè®¡
    count_df = pd.DataFrame(count_stats)
    count_df.to_excel(os.path.join(result_dir, "cell_count_summary.xlsx"), index=False)

    # 3. ç»˜åˆ¶æ‰€æœ‰å¹³æ»‘åçš„ç›´æ–¹å›¾
    plt.figure(figsize=(16, 8))
    cmap = get_cmap("tab20", len(histograms))
    x = bin_centers
    ref_smooth = gaussian_filter1d(ref_hist, sigma=2)
    plt.plot(x, ref_smooth, label=f'{REFERENCE_FOLDER}_{REFERENCE_DATA} (ref)', color='black', linewidth=2, zorder=10)
    for idx2, (folder_key, hist) in enumerate(histograms.items()):
        smooth = gaussian_filter1d(hist, sigma=2)
        color = cmap(idx2)
        plt.plot(x, smooth, label=folder_key, color=color, alpha=0.85)
    plt.title(f"DATASET2 - Smoothed Area Distribution Histogram Curves\nRef={REFERENCE_FOLDER}_{REFERENCE_DATA} (30%)")
    plt.xlabel("Cell Area")
    plt.ylabel("Normalized Frequency")
    plt.legend(fontsize=8)
    plt.tight_layout()
    plt.savefig(os.path.join(result_dir, "all_histograms_smoothed.png"), dpi=300, bbox_inches='tight')
    plt.close()

    # 4. è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_data = []
    for folder_key, hist in histograms.items():
        similarity_data.append({
            "Compared Folder": folder_key,
            "Histogram Intersection": compute_histogram_similarity(ref_hist, hist, 'intersection'),
            "KL Divergence": compute_histogram_similarity(ref_hist, hist, 'kl')
        })
    similarity_df = pd.DataFrame(similarity_data)
    similarity_df_inter = similarity_df.sort_values(by="Histogram Intersection", ascending=False)
    similarity_df_kl = similarity_df.sort_values(by="KL Divergence", ascending=True)
    excel_path = os.path.join(result_dir, "histogram_similarity_results.xlsx")
    with pd.ExcelWriter(excel_path) as writer:
        similarity_df_inter.to_excel(writer, sheet_name='Intersection', index=False)
        similarity_df_kl.to_excel(writer, sheet_name='KL', index=False)

    # 5. è¾“å‡ºç»“æœ
    print(f"\nğŸ“Š DATASET2 Similarity Analysis Results:")
    print(f"å‚è€ƒæ ·æœ¬: {REFERENCE_FOLDER}_{REFERENCE_DATA}")
    print(f"æ€»æ ·æœ¬æ•°: {len(histograms)}")
    print(f"åˆ†æèŒƒå›´: {RANGE[0]}-{RANGE[1]} åƒç´ ")

    # è¾“å‡ºTOP3åŠåŒºåˆ†åº¦
    print(f"\nğŸ” Histogram Intersection TOP3:")
    top_inter = similarity_df_inter.head(3)
    for i, row in enumerate(top_inter.itertuples(), 1):
        print(f"{i}. {row._1}: {row._2:.4f}")
    if len(top_inter) >= 2:
        diff12 = (top_inter.iloc[0]['Histogram Intersection'] - top_inter.iloc[1]['Histogram Intersection']) / top_inter.iloc[0]['Histogram Intersection']
        print(f"åŒºåˆ†åº¦1-2: {(diff12*100):.2f}%")
    if len(top_inter) >= 3:
        diff23 = (top_inter.iloc[1]['Histogram Intersection'] - top_inter.iloc[2]['Histogram Intersection']) / top_inter.iloc[1]['Histogram Intersection']
        print(f"åŒºåˆ†åº¦2-3: {(diff23*100):.2f}%")

    print(f"\nğŸ” KL Divergence TOP3:")
    top_kl = similarity_df_kl.head(3)
    for i, row in enumerate(top_kl.itertuples(), 1):
        print(f"{i}. {row._1}: {row._3:.4f}")
    if len(top_kl) >= 2:
        diff12 = (top_kl.iloc[1]['KL Divergence'] - top_kl.iloc[0]['KL Divergence']) / top_kl.iloc[0]['KL Divergence']
        print(f"åŒºåˆ†åº¦1-2: {(diff12*100):.2f}%")
    if len(top_kl) >= 3:
        diff23 = (top_kl.iloc[2]['KL Divergence'] - top_kl.iloc[1]['KL Divergence']) / top_kl.iloc[1]['KL Divergence']
        print(f"åŒºåˆ†åº¦2-3: {(diff23*100):.2f}%")

    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ° {result_dir}/ æ–‡ä»¶å¤¹")
    print(f"   - cell_count_summary.xlsx: ç»†èƒæ•°é‡ç»Ÿè®¡")
    print(f"   - histogram_similarity_results.xlsx: ç›¸ä¼¼åº¦åˆ†æç»“æœ")
    print(f"   - all_histograms_smoothed.png: ç›´æ–¹å›¾å¯¹æ¯”å›¾") 